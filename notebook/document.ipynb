{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9ffc4e",
   "metadata": {},
   "source": [
    "### Data Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ab50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### document datastructure\n",
    "\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adadd6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'notebook/document.ipynb', 'pages': 1, 'author': 'Diego Olmedo', 'date_created': '2024-06-10'}, page_content='This is the content of the document i am using to create RAG systems.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc=Document(\n",
    "    page_content=\"This is the content of the document i am using to create RAG systems.\",\n",
    "    metadata={\n",
    "        \"source\": \"notebook/document.ipynb\",\n",
    "        \"pages\": 1,\n",
    "        \"author\": \"Diego Olmedo\",\n",
    "        \"date_created\": \"2024-06-10\"\n",
    "        }\n",
    ")\n",
    "\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4bd870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creando un archivo txt sencillo\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f24dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos de texto creados correctamente en ../data/text_files/\n"
     ]
    }
   ],
   "source": [
    "# Definir los textos de ejemplo\n",
    "sample_texts = {\n",
    "    \"../data/text_files/documento1.txt\": \"\"\"Sistema RAG (Retrieval-Augmented Generation)\n",
    "El sistema RAG es una arquitectura que combina la recuperación de información con la generación de texto.\n",
    "Este enfoque permite mejorar la precisión y confiabilidad de las respuestas del modelo.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/documento2.txt\": \"\"\"Procesamiento de Lenguaje Natural\n",
    "El PLN es un campo de la inteligencia artificial que se centra en la interacción entre las computadoras y el lenguaje humano.\n",
    "Es fundamental para aplicaciones como traducción automática, análisis de sentimiento y sistemas de pregunta-respuesta.\"\"\"\n",
    "}\n",
    "\n",
    "# Crear los archivos\n",
    "for filepath, content in sample_texts.items():\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Archivos de texto creados correctamente en ../data/text_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "063e3abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegoolmedocr/Documents/RAG/mi_proyecto/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/documento1.txt'}, page_content='Sistema RAG (Retrieval-Augmented Generation)\\nEl sistema RAG es una arquitectura que combina la recuperación de información con la generación de texto.\\nEste enfoque permite mejorar la precisión y confiabilidad de las respuestas del modelo.')]\n"
     ]
    }
   ],
   "source": [
    "### TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/documento1.txt\", encoding=\"utf-8\")\n",
    "document = loader.load()\n",
    "\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bdbf46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/documento2.txt'}, page_content='Procesamiento de Lenguaje Natural\\nEl PLN es un campo de la inteligencia artificial que se centra en la interacción entre las computadoras y el lenguaje humano.\\nEs fundamental para aplicaciones como traducción automática, análisis de sentimiento y sistemas de pregunta-respuesta.'), Document(metadata={'source': '../data/text_files/documento1.txt'}, page_content='Sistema RAG (Retrieval-Augmented Generation)\\nEl sistema RAG es una arquitectura que combina la recuperación de información con la generación de texto.\\nEste enfoque permite mejorar la precisión y confiabilidad de las respuestas del modelo.')]\n"
     ]
    }
   ],
   "source": [
    "### Directory Loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files/\",\n",
    "    glob=\"*.txt\", # Cargar solo archivos .txt -> este es el patron a matchear\n",
    "    loader_cls=TextLoader, # Clase de cargador a usar\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"} ,# Argumentos para el cargador\n",
    "    show_progress=False # Mostrar progreso de carga)\n",
    ")\n",
    "\n",
    "documents = dir_loader.load()\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33057a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/STAR stories.pdf', 'file_path': '../data/pdf/STAR stories.pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'STAR stories', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='Historia 1: “Automatizando la Validación de CPLDs con \\nIA Local” \\n(Principios: Invent and Simplify | Deliver Results | Ownership) \\nS – Situation \\nDurante la etapa crítica de validación del nuevo servidor Xeon, el proceso manual de \\nvalidación de CPLDs tomaba más de 10 horas por build. Cada iteración dependía de scripts \\nfragmentados y validaciones manuales, generando errores humanos y retrasos \\nsignificativos justo antes del Power On. \\nT – Task \\nComo ingeniero senior de automatización, debía diseñar un sistema que redujera los \\ntiempos de validación y permitiera detectar defectos pre-silicon con total trazabilidad, sin \\ndepender de herramientas propietarias externas. \\nA – Action \\n●\\u200b Diseñé una arquitectura híbrida en Python y C sobre una Raspberry Pi 5, creando \\nun sistema completamente autónomo para ejecutar más de 1 000 vectores JTAG \\npor build. \\n●\\u200b Integré un modelo de lenguaje local (SLM Phi-3.5 mini) mediante Ollama, que \\nactuaba como asistente de validación y corrección de código, permitiendo \\nrespuestas inmediatas sin conexión a la nube. \\n●\\u200b Implementé Azure CI/CD pipelines y una suite de unit tests con >90 % de \\ncobertura, asegurando calidad y reproducibilidad en cada release. \\n●\\u200b Lideré la integración en laboratorio, coordinando con los equipos de firmware y \\nvalidación para desplegar el sistema en solo dos días durante la ventana crítica de \\nPower On. \\nR – Result \\n●\\u200b Reduje el ciclo de validación de 10 horas a 1 hora, acelerando el pattern release \\nen 90 %. \\n●\\u200b Detectamos 3 defectos críticos pre-silicon, evitando fallas costosas en la etapa \\nde bring-up. \\n●\\u200b Logramos un 100 % de pass yield en muestras de ingeniería. \\n●\\u200b La solución fue adoptada como referencia global para validación inteligente con IA \\nlocal, y estableció la base para futuras integraciones de agentes en flujos de \\nhardware.'), Document(metadata={'producer': 'Skia/PDF m143 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/STAR stories.pdf', 'file_path': '../data/pdf/STAR stories.pdf', 'total_pages': 2, 'format': 'PDF 1.4', 'title': 'STAR stories', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='Historia 2: “El Primer Lanzamiento a Tiempo en una \\nDécada” \\n(Principios: Deliver Results | Ownership | Earn Trust | Dive Deep) \\nS – Situation \\nEl programa de la 5.ª Generación Xeon enfrentaba múltiples retrasos acumulados en \\ndesarrollo y pruebas. Históricamente, ninguna generación anterior había alcanzado el \\ntime-to-market prometido. Los cuellos de botella en automatización y comunicación entre \\nequipos globales amenazaban con repetir el patrón. \\nT – Task \\nComo Product Owner y Tech Lead, debía coordinar equipos de diseño, validación y \\nmanufactura en tres países, mejorar la eficiencia de los flujos de automatización y asegurar \\nun entregable a tiempo por primera vez en 10 años. \\nA – Action \\n●\\u200b Introduje prácticas de Agile/Scrum en un entorno tradicionalmente rígido, \\nimplementando Jira y CA Agile Central para gestionar backlogs y velocity metrics. \\n●\\u200b Definí KPIs claros para desarrollo y pruebas, identificando barreras de comunicación \\nentre ingeniería de planta y laboratorio. \\n●\\u200b Lideré la creación de un nuevo flujo de validación automatizado en Python y C#, \\nreduciendo tiempos de testing en 25 % y aumentando eficiencia operativa en 15 %. \\n●\\u200b Desarrollé una herramienta de analítica (“Retest QBot”) para eliminar retests \\ninnecesarios, conectada a bases de datos de manufactura vía MSAL/Azure API con \\nautenticación segura. \\n●\\u200b Fomenté una cultura de confianza entre equipos globales (Santa Clara, Austin y \\nCosta Rica), promoviendo transparencia y aprendizaje continuo. \\nR – Result \\n●\\u200b El equipo logró el primer lanzamiento puntual en 10 años, acelerando la línea de \\ntiempo en 6 semanas. \\n●\\u200b Se obtuvieron mejoras de 30 % en métricas de desarrollo, 20–40 % en \\nrendimiento y >30 % en eficiencia energética del producto. \\n●\\u200b Fui reconocido con el Intel Achievement Award por liderazgo y entrega excepcional \\nde resultados. \\n●\\u200b La cultura de entregables a tiempo y colaboración fue adoptada como estándar \\nregional para proyectos posteriores.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content='Tanishq Arora'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1}, page_content='Introduction\\nDevops and Site Reliability Engineers are in demand in the industry because as the scale or\\nyour production system increases you need people who can understand the importance of\\nhaving a good infrastructure and automation. There are a lot of shifts in the industry and\\nsoftware engineers tend to move towards devops or site reliability engineering in recent\\ntimes. It can be a tough transition sometimes and you need to learn linux systems and\\nnetworking properly to be able to be successful in this field.\\nIn this book, I tried to give you the points that you should read before going for an interview\\nfor SRE or devops. Don’t consider this a comprehensive book for reading about those\\ntopics. It is very important to know what you should read and the motive of the book is the\\nsame, this book is to give you pointers to what you read.\\nIt will also tell you about the rounds that happen in general Devops and Site Reliability\\nEngineer interviews. This book covers topics like basic programming, Linux systems and\\nnetworking, tools in devops, basic troubleshooting, code review and incident management.\\nHow to read this book?\\nGo through the questions and once you find a topic that you don’t understand give it a look.\\nMost of the topics in linux you can actually read in 10-20 min if we exclude networking. So if\\nyou are not able to solve the question read the topics and attempt again.\\nWho should read this book?\\nAnyone who has an interview scheduled in less than a week, this week will help you in the\\nfinal revision of your preparations. Please note that good understanding of networking and\\nlinux takes a good amount of reading and working experience. I highly recommend people\\nwho want to move to this field to go through and read them as much as possible.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2}, page_content=\"Linux Commands and python Tricks.\\n●\\nDo you know about procfs?\\nProcfs or proc filesystem in unix-like systems keeps track of the processes that run\\nand other systems information like memory, CPU, IO. You can find all this detail in\\n/proc directory and each directory inside it is actually PID of the processes running. If\\nyou go inside these directories you will be able to get the information related to the\\nprocess. These files don't have any size as these are generated on the run time.\\n●\\nDo you know about tmpfs?\\nTemp fs or temporary file system is generally used as temporary memory. It appears\\nas it is mounted but is actually a space in volatile memory. Thus everything that is in\\n/tmp will be deleted once the machine reboots. It is in volatile memory so it is fast and\\nshort lived.\\n●\\nHow to change the hostname of the machine?\\nYou can use this command to change the hostname of the system.\\nsudo hostname new_hostname\\nThis change will be overridden on reboot for that you have to change the value in\\n/etc/hostname and make a corresponding entry in /etc/hosts to map to 127.0.0.1\\n●\\nHow to get free memory?\\nfree -m\\n●\\nHow to get disk space usage?\\ndf -h [-h for human readable format]\\n●\\nHow to create an empty file?\\ntouch filename\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3}, page_content=\"●\\nWhere are the config files of most servers stored?\\nConfigs can generally be found in /etc. But it is not mandatory you can override to\\nconfigs from any place\\n●\\nDifference between TCP and UDP?\\nTCP: Also known as Transmission control protocol makes sure that the connection\\nestablished between two hosts is reliable and also takes care of the orders in which\\npackets will receive and retry if the packet delivery fails. To make the connection it\\nalso does a three way handshake to establish proper connection which also makes it\\nslower than UDP. Reliability is added by acknowledgements and retries that TCP\\nattempts to fulfil.\\nUDP: In contrast User Datagram protocol doesn't take care of any of these, it just\\nsends the data and forget about it. It is fast and unreliable.\\n●\\nIs IP a reliable protocol?\\nNo, Internet protocol is best effort delivery, it does not ensure your packet will reach.\\nAdding TCP with IP makes it reliable.\\n●\\nWhat makes TCP/IP a reliable protocol?\\nFeatures like retransmission of packet when it is lost and inorder delivery of packets\\nand acknowledgements makes TCP/IP a reliable protocol.\\n●\\nWhat is a Three way handshake?\\nThree way handshake is a mechanism by which TCP establishes a connection with\\nother computers. By this the client and server are aware of some basic information\\nthat is needed for data transfer.\\nHere are the exact steps:\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4}, page_content='1. A client node sends a SYN data packet to a server on the same or an\\nexternal network. This packet is to ask if the server is open for new\\nconnections.\\n2. The server must have open ports that can accept and initiate connections.\\nWhen the server receives the SYN packet from the client, it responds and\\nreturns a confirmation SYN/ACK packet.\\n3. The client receives the SYN/ACK from the server and responds with an ACK\\npacket.\\nThese are the three steps in a three way handshake.\\n●\\nWhat does shebang tell? [#!/bin/bash]\\nShebang tells which interpreter path to use while running the script.\\n●\\nHow to check the connection between two machines?\\nIt checks the connection whether anything is running on that port. You can test on\\nthe localhost also by using\\ntelnet host port.\\n●\\nHow to see what all ports processes are running?\\nnetstat -pln [p for process ID, L for listening port since program is listening and n for\\nnumerical address instead of host]\\n●\\nHow to see the last updated file in a directory?\\nYou can do ls -ltr and the files are sorted by time.\\n●\\nWhat do you mean by load average that you see?\\nLoad average is the average number of tasks that are waiting in the queue for the\\nCPU time.\\n●\\nWhat does the 3 numbers in load average specify?'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5}, page_content='First number is the last one min average, second is 5 min average and third one is\\n15 min average.\\n●\\nWhat is OOM?\\nOOM is Out of Memory Error. You get this error when a program needs memory and\\nthere is no free memory to allocate to it.\\n●\\nWhat is isolation of resources and how you can accomplish it?\\nBy isolation we mean that we want to isolate one entity from the other, this entity can\\nbe a resource like memory, cpu or processes. You can implement it in Linux using an\\nunshare command.\\n●\\nWhat are containers?\\nContainers are isolation that helps you in running a process in its own namespace\\nwith proper restrictions on resources that it can use. This helps you in better\\nutilization of the resources and it also helps in keeping one process not affected from\\nthe other process.\\n●\\nWhat is a socket?\\nSocket is a combination of port + ip + protocol. Sockets allow communication\\nbetween two processes on the same or different hosts that are connected by\\ninternet.\\n●\\nHow many IPS are there in 10.28.0.0/16 CIDR?\\nThis will be 2^32-16 IP which is 2^16 = 65536\\n●\\nWhat could be the architecture of a VPC and its subnets?\\nBelow can be the architecture:'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6}, page_content='VPC with cidr something like 10.30.0.0/16\\nAfter that you need subnets for private and public machines. In a private subnet you\\nkeep machines which are private like databases or application machines. In the\\npublic subnet you keep the public load balancers and jump boxes, which you need to\\nbe accessible from the public.\\nYou may need a nat box for you machines in a private subnet to access the internet.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7}, page_content='●\\nWhat is a reverse proxy?\\nIn reverse proxy, the client makes requests to the proxy and the proxy internally can\\nmake requests to multiple servers configured and return the response to the client. In\\nthis case the reverse proxy is protecting the original servers by not allowing the\\nclients to know about them. In this case the client thinks that all the requests are\\nserved by the reverse proxy but in behind there can be many servers running and\\nreturning the resource you need. Examples of Reverse Proxy are - Nginx, HAProxy.\\n●\\nWhat is a forward proxy?\\nForward proxy can be used to control and can imply restriction on  the traffic from the\\ngroup of clients. For example if you want to restrict any site from your organization\\nyou can enable a forward proxy and then you will have to put restrictions on one\\ncentral place. Example of forward proxy is squid proxy\\n●\\nWhat is DNS load balancing?\\nDNS load balancing is used to allow the traffic to be distributed to different servers\\nwith the help of DNS servers. In this the DNS query resolves to multiple IP\\naddresses in random order thus distributing the traffic.\\nIt is done by resolving a DNS to multiple IP addresses, for this you make these\\nentries a DNS server that this DNS should resolve to these IPs.\\n●\\nHow many Root DNS servers are there in the world?\\nThere are a total of 13 Root server IPs in the world. There are multiple servers\\nbehind these ips and they use any cast for this.\\n●\\nWhy are there only 13 root nameservers?'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8}, page_content='The DNS packet is 512 Bytes[Limited at the time of DNS infrastructure decisions],\\nwith each IP address having 32 bytes for 13 total data is 416 bytes. 96 bytes are left\\nfor other data or IP to be added in future.\\n●\\nWhy does DNS use UDP?\\nIt uses UDP because it is fast and these packets are small. We need DNS resolution\\nto be fast.\\n●\\nCan DNS work on TCP?\\nYes it can work on TCP also but it will be slow due to the 3 way handshake.\\n●\\nWhat does the /etc/resolv.conf file contain?\\nIt contains the configuration of the nameservers that our machine will query to and\\nother options like timeout and retries.\\n●\\nWhat are Cgroups?\\nCgroups are linux kernel features which give functionality to restrict the amount of\\nresources that can be used by any process. These resources can be CPU, memory,\\nIO, network bandwidth etc.\\n●\\nWhat are runlevels?\\nRunlevels are the modes in which your system will boot in. There are 7 runlevels\\nfrom 0-6\\n0: HALT\\n1: Single User No network\\n2: Multiple User No network\\n3: MultiUser networking'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9}, page_content='4: User defined, Generally not used.\\n5: Most of the desktop displays with networking.\\n6: Reboot\\n●\\nHow to create a file and its recurring directory like /etc/test/innertest/file\\nmkdir -p\\n●\\nWhat are inodes?\\nInodes are the data structure that keeps all the metadata about any file. You can see\\ninode numbers using ls -i\\n●\\nWhat is NAT?\\nNAT (Network Address translator) is generally used when you want to hide one side\\nof the network and show it as a single IP. NAT keeps a connection table so that it can\\nforward the returning traffic to the private location. NAT makes changes to either\\nsource or the destination address in headers and then forwards the packet.\\n●\\nWhere do we use NAT?\\nWe use NAT where we want the world to see all of our machines under one IP\\naddress because of cases like whitelisting to particular resources etc. All you\\nmachine’s traffic goes through NAT to the world with the NAT box ips so they can\\nidentify that traffic as yours.\\n●\\nWhat type of NATs are there?\\nSNAT:\\nIn this type of NAT, the source IP of the packet changes and then passes it to the i\\ninterface. In this case, the destination will not be able to see who actually created the\\nrequests. SNAT allows hosts inside to connect to particular host outside.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10}, page_content='All the hosts behind the SNAT are identified as one entity. This helps in scenarios\\nwhere you want the third parties to whitelist your IP so that they can identify you\\nDNAT:\\nThese are the NATs where destination IPs are changed in headers and then passed\\nto the interface. DNAT allows hosts from outside to connect to a particular host\\ninside.\\nThis can be used in the example where you want to host it something locally with\\nprivate ip and want your NAT box to forward to this host whenever someone tries to\\ncontact to NAT IP\\n●\\nWhat do you mean by ssl offloading?\\nSSL offloading is  the processing of getting the data from the encrypted traffic which\\nis sent using https using ssl. To read more about SSL and how it works you can read\\nabout public key encryption.\\n●\\nHow to check your distribution and version of you os?\\nlsb_release -a\\n●\\nHow to check kernel version?\\nuname -a\\n●\\nHow to count all the opened files by os?\\nlsof | wc -l\\n●\\nHow to figure out process ID running with name apache?\\nps -ef| grep apache'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 11}, page_content='●\\nHow to kill process with process ID 4?\\nkill -9 4\\n●\\nHow to check the uptime of your machine?\\nYou can see it by typing the command w.\\n●\\nWhat is the below permission specified? -rw-rw-r—\\nThis means User that owns it can read and write but not execute, groups that own it\\nread and write but cannot execute and others can only read it.\\n●\\nWhat does d say here in permissions? drwx------\\nIt notifies that it is a directory.\\n●\\nHow to continuously keep a look at the command and say you want to run it\\nevery 2 seconds?\\nwatch -n2 command\\n●\\nHow does DNS resolution happen?\\nWhenever there is a request to resolve the dns below are the following steps that\\nare taken in sequence.\\n1. Checks the hosts file for any entry for that hostname\\n2. Check the local dns cache for any entry\\n3. Next it is checked if the DNS is present with your internet provider.\\n4. If not, root servers are contacted.\\n5. Root servers then tell you about the next server to look into for the dns.Root\\nservers know all the details about the TLDs i.e. top level domains like .com,\\n.in etc. It may not know about google.com but it will know .com might have\\nthat information so it returns that.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 12}, page_content='6. Next .com is queried if google.com is with it or not. If not .com will keep the\\ninformation of the nameservers which keeps the information about\\ngoogle.com and return them.\\n7. Those servers are then queried to get the google.com mapped to an ip\\naddress.\\n●\\nHow can you make a request using a terminal?\\nYou can use curl to make a request for something like this. curl host:port/resource\\n●\\nWhich process has Process ID 1?\\nInit process has process id 1. It is the first process that is launched after the boot\\nprocess.\\n●\\nWhat is the normal size of a packet in a network?\\nStandard ethernet frame is 1518 bytes in size.\\n●\\nWhat are jumbo frames?\\nJumbo frames are ethernet frames that are bigger than 1518 bytes.\\n●\\nWhat is swap memory?\\nSwap memory is a way to increase virtual memory available to the host. What\\nhappens is it creates a swap partition and uses it along with RAM. Whenever RAM is\\nfull and a new process needs to be executed [Page Fault], the kernel takes a few\\npages out of the RAM and puts it in swap memory and uses the RAM for the next\\nprocess. Once it needs the swapped out page back it can read from the swap space\\nand put it back in memory.\\n●\\nWhat is a softlink?'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 13}, page_content='Soft Links are symbolic links to a file or folder in the linux system. It actually is\\nnothing but a reference to the exact object. You can create soft links using these\\ncommands\\nln -s source[file_to_link] destination[link]\\n●\\nWhat is the port used by SSH?\\n22\\n●\\nWhat is the port used by DNS?\\n53\\n●\\nHow can you get the number of threads spawned by process id 10?\\nYou can see the content of file /proc/10/status\\nYou can see a like num_threads that tells you about the number of threads for that\\nprocess.\\n●\\nWhere can you find syslogs?\\n/var/log/syslog\\n●\\nWhat is systemd?\\nSystemd is a system and service manager for linux systems. It is the first process to\\ncome up after a successful boot process. Systemd takes care of all the services that\\nneed to be started after boot. It actually replaces the old generation init system\\nprocess.\\nIt has few advantages over older init like it can launch processes in parallel, you can\\nhave post and pre scripts and optional scripts. It also has components like journald\\nwhich takes care of logging.\\n●\\nWhat is journald?'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 14}, page_content='Journald is a service in systemd which collects aggregates and provides functionality\\nto view those logs.\\n●\\nWhere can you see the auth logs in the linux system ?\\nThis file logs all the events related to authentication and authorization.\\n/var/log/auth.log\\n●\\nWhat are crontabs?\\nCrontab is a command used to edit the commands table that is run by cron. Crons\\nare the commands that you want to run after a particular interval or a particular\\nschedule.\\n●\\nHow to run a script 5th minutes every hour?\\nThis is the format used to represent crontab * * * * * . First asterisk is minute, second\\nis hour, third is day of month, fourth is year and fifth is day of week. Also there are 4\\nstandard commands * for any value, ‘,’ for value list separator, ‘-’ for range of values\\nand ‘/’ for step values.\\nBelow is the answer to the question.\\n5 * * * * command. Read about the other asterisk as well.\\n●\\nWhat are the standard file descriptors?\\nThe standard file descriptor are Stdin, stdout and stderr\\n●\\nHow to write “Hello” to a file without opening it?\\necho “Hello” >> filename\\n●\\nWhat is /dev/null?'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 15}, page_content=\"It is a special file in linux also called a null device. It can act as a blackhole means\\nanything written to it is discarded instantly. It only returns EOF [end of file] when read\\nfrom it.\\n●\\nWhat are lightweight processes in linux?\\nLight weight processes are also called threads.\\n●\\nWhat is the difference between a thread and a process?\\nThreads are lighter than process. Process has its own heap memory call stack and\\nprogram counter while threads only have call stack and program counter they share\\nthe memory heap from the process to which it is spawned.\\n●\\nHow can you see if IP forwarding is enabled or not?\\nsysctl net.ipv4.ip_forward or you can read the content of the file\\n/proc/sys/net/ipv4/ip_forward\\n●\\nHow to replace a few characters in file without opening it?\\nsed -i 's/old-text/new-text/g' filename\\n●\\nHow to trace the route a packet is taking to reach an IP?\\nYou can use the traceroute utility. traceroute ip command will do it for you.\\n●\\nHow to change the owner of a file?\\nchown user:group filename\\n●\\nWhat is nohup?\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 16}, page_content='It is used to run any command as a daemon or background process.It ignores the\\nHUP signal.\\n●\\nHow to see the top 10 lines of a file?\\nhead -n 10 filename\\n●\\nHow to see the Bottom 10 lines of a file?\\ntail -n 10 filename\\n●\\nHow to count the number of lines that are there in a file?\\ncat filename| wc -l\\n●\\nHow to see the directory path you are in?\\npwd\\n●\\nWhat are daemons?\\nDaemons are process that keeps running in background. These process get\\nrestarted by itself if killed or terminated. In linux these process are named as\\nprocessd like initd, systemd, journald etc.\\n●\\nHow can you see the commands previously ran for that user?\\nhistory\\n●\\nHow to list all mounted devices?\\nmount -l\\n●\\nHow to see the status code of the last command you executed?\\nTo see the last command executed you try this command  `$?`. Note: This is not a\\nprinting error'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 17}, page_content='●\\nHow to see all the environment variables?\\nexport\\n●\\nHow to set a new environment variable?\\nexport name=value . This will temporarily save the env variable. If you want to use\\nenv variable whenever you launch shell you can put in your bash.rc or\\nbash_profile.rc files.\\n●\\nHow to see the number of CPUs?\\nnproc\\n●\\nWhat are huge pages?\\nHuge pages are the pages that are larger than the normal convention of the linux\\nsystem which is 4KB by default. You can see it by getconf PAGESIZE. Huge pages\\ncan vary from 2MB to 256 MB. It also depends on the kernel version.\\n●\\nWhat do you mean by loopback ip?\\nIts localhost ip which is 127.0.0.1\\n●\\nHow to list all the corn tabs and how to edit?\\nTo list all cron tabs you can use crontab -l and to edit them you can use crontab -e\\n●\\nHow to run a program as a background task?\\nYou can use nohup or append & at the end of command to run the program.\\n●\\nHow to list tasks running in the background?\\nYou can use the `jobs` command to do that.\\nTry opening a file to exit and then press ctrl+z. This will put the process in the\\nbackground now when you types job you will be able to see this process.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 18}, page_content=\"●\\nHow to bring the background task to foreground?\\nYou can use\\n`fg %n`\\ncommand to get the task from background to terminal. N is the task number which\\nyou get when you run bg.\\n●\\nWhat command do you use to see the boot messages?\\ndmesg will show all the boot messages.\\n●\\nHow to change the nameserver you want your machine to query to while\\nresolving dns?\\nYou can change it by editing /etc/resolv.conf file and adding your nameservers like\\nthis\\nnameserver ip1\\nnameserver ip2\\n●\\nWhat do you mean by CPU intensive process?\\nCPU intensive processes are those which need a lot of CPU time for the work that\\nthey are doing. CPU intensive tasks are calculations like generating prime numbers\\netc.\\n●\\nWhat do you mean by the IO intensive process?\\nThese are the processes that depend a lot on IO. These include read write from disk\\nor buffer network calls etc.\\n●\\nHow to list processes which are consuming the most CPU?\\nps aux| awk '{print $3, $2, $11}' | head -n 15\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 19}, page_content='●\\nWhich file to check for if the user exists or not?\\n/etc/passwd\\n●\\nHow to stream the content of a file which is being written continuously?\\ntail -f filename\\n●\\nWhat are iptables?\\nIptables is a utility that is used to set, maintain and inspect the tables for IP packet\\nfilter rules in linux kernel\\n●\\nHow to list all iptables rules?\\niptables -L\\n●\\nWhat is the name of a utility to take care of log rotation?\\nlogrotated\\n●\\nHow to check your file system for any errors?\\nfsck\\n●\\nHow can you block all the packets coming from a particular IP?\\niptables -A INPUT -s ipaddress -j DROP\\n●\\nHow to see all the packets going to a particular IP?\\nYou can use tcpdump utility. These commands will help you to see those packets.\\ntcpdump -i eth0 src ipaddress\\n●\\nWhat is a TCP dump?\\nTcpdump is a tool to see the network packets and apply filters to those. You can also\\nsave the capture and see it later. It is widely used for packet analysis.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 20}, page_content='●\\nWhat happens when you type init 6?\\nSystem reboot\\n●\\nHow to see all the logs after last boot in systemd ?\\njournalctl -b\\n●\\nWhich port https works on?\\n443\\n●\\nWhat is a sticky bit?\\nWhen you set the sticky bit only the owner of the file can delete it.\\n●\\nDo you know about “at”?\\nWith “at” you can schedule a task but it will run only once.\\n●\\nWhat is cloud init?\\nCloud init is the command that runs and bootstrap the machine in cloud\\nenvironments. Cloud init can run any bash commands. Generally these are used to\\nprovision the machines when they come up. So whenever you launch a machine in\\nany cloud provider, they give you the option to run a cloud init script.\\n●\\nWhat are unit files?\\nUnit file is a systemd file with which you can manage any particular service. Once\\nyou create this file for any commands you will be able to use systemd commands\\nwith it like sysctl service restart etc.\\n●\\nWhat is runc ?\\nRunc is a component of containers which takes care of creating the containers. It\\ndoes cgroups, unshare and other operations needed to create a container.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 21}, page_content='●\\nWhat are shim containers?\\nWhen you try to launch a container, the flow is containerd asks containerd-shim to\\nlaunch container which calls runc to create container and then exits leaving a few of\\nthe things like file descriptors so that container can pass essential signals to\\ncontainerd-shim.\\nIts main purpose is to pass the important signals to the containerd.\\n●\\nWhat do you know about CNI is kubernetes?\\nThe Container Network Interface (CNI) is a library definition, and a set of tools under\\nthe umbrella of the Cloud Native Computing Foundation (CNCF)project.\\nCNI is an interface between network providers and kubernetes networking. Few of\\nthe CNI are callico, cillium, kube-router etc.\\n●\\nWhat do you know about OCI?\\nOCI or open container initiative is  a foundation to design the open standard for\\ncontainers. The project is to focus on developing standard interfaces which if\\nsomeone follows can replace docker in kubernetes or other orchestrators  with some\\nother container implementation which follows the same standards.  Currently it has\\ntwo specifications, runtime specification and image specification.\\n●\\nTwo containers in one pod can talk to each other with what ip?\\n127.0.0.1 or localhost. For Example if a container  is running on port 8080 then other\\ncontainer can  access it using  localhost:8080 or 127.0.0.1:8080\\n●\\nWhat is a veth pair?'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 22}, page_content=\"Veth pair is just like a network wire. It is two virtual ethernet interfaces. It is used to\\nconnect two devices like bridge to bridge or bridge to container. It is done by placing\\none end of the veth pair in the container's namespace and the other in the bridge.\\n●\\nWhat do you mean by VPC peering?\\nVPC peering is connecting two VPC so that machines in one VPC can access the\\nmachines in another VPC like a private network. One thing that you have to keep in\\nmind is that their cidr should not overlap.\\n●\\nWhat do you understand by IAAC?\\nInfrastructure as a code is a process by which you define your infrastructure as a\\ndefinition files in code using one or the other way. It is a process to make the\\nmanagement of infrastructure easy. The main benefit of IAAC comes when you\\ndefine everything using code and put it in VCS(Version Control System like git). It\\nbecomes very easy to track changes in the infrastructure.\\n●\\nAccording to you what are the important components that every software\\nshould have?\\nImportant components can be logging, monitoring, alerting, exception reporting,\\ncontinuous integration, test cases and documentation. These are few important\\ncomponents that any software should have. You can also read about 12 factor\\napplications. It contains standards that you can follow. .\\n●\\nHow much should an application log?\\nWhen you talk about logging in application you have to keep this in mind that if you\\nlog too much you application will be busy most of the time logging stuff. If it is too\\nless then you may miss small errors that should be caught by looking at logs. Thus,\\nthe amount of logging is very important. There are some default log levels that are\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 23}, page_content='supported by most of the languages and frameworks. These are default, debug, info,\\nerror, warning and critical. In general you log level should be error but should be\\ndynamically configurable so that if you see problems you can change the log level to\\ndebug and see the logs. Changing the log levels dynamically is tough to implement\\nbut it is a great feature to have.\\n●\\nWhich port ping works on?\\n22\\n●\\nWhat is the maximum size any filename can have in linux?\\n255 characters\\n●\\nHow to see what system calls are being executed by a process?\\nstrace utility can be used for the same\\n●\\nWhat is a nice value of a process?\\nNice command is used to change the niceness of the process, a nice range lies\\nbetween -20 to 19. Nice add priority to the process execution. Nice is priority by user\\nand priority is by kernel. PR[Priority] = 20 + NI [NICE]. So with nice you can actually\\nask the kernel to process your tasks before a few of the lower priority kernel\\nassigned tasks.\\n●\\nWhat is redirection in linux?\\nRedirection is a way to change the input, output and error standard devices.\\n●\\nWhat types of redirections are there?\\nThere are three types of redirection:\\n1. Input redirection\\n2. Output redirection\\n3. Error redirection'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 24}, page_content='●\\nHow to see if the DNS is getting resolved or not?\\nYou can use dig or nslookup commands. In dig you have to look for the answer\\nsection. In nslookup you can look for the address section.\\n●\\nHow to see which nameservers are used for dns resolution?\\nYou can use dig +trace to get the trace of all the nameserver that are getting called\\nin resolution\\n●\\nYou have a very huge file which command will you use to see the file content?\\nless utility can be used for this purpose.\\n●\\nWhat is the difference between > and >> operator?\\n‘>’ operator is used for writing files from the start.\\n‘>>’ appends to the file.\\n●\\nWhat happens when you type this command on a file with one line?  Cat\\nfilename> filename\\nIt will be an empty file. This will happen because when you use > you file is opened\\nfor writing. And a descriptor will be returned. Another descriptor is from cat command\\nwhich is used to read the file. When you open a file it will be empty so you write\\nnothing to the opened file descriptor.\\n●\\nWhat happens when you do cat filename>> filename?\\nIt will be an infinite loop in which your file is appended with a test in each loop. A file\\ndescriptor will keep writing and another will keep reading to the same file and writing\\nit back so it will be an infinite loop.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 25}, page_content='●\\nWhat does home directory contain?\\nHome directory contains all the users information that is there in the system like\\nkeys.\\n●\\nYou have to give ssh permission to a user, you have his public key how will\\nyou do it?\\nYou can add the public key in .ssh/authorized_keys and it will give the user access.\\n●\\nWhat does the known_hosts file do?\\nIt contains the signature of the hosts that have accessed it.\\n●\\nWhat do you know about CAP theorem?\\nCAP theorem states that among Consistency, Availability and Partitioning it is only\\npossible to get two of them at a time. It can be kept in mind when designing a very\\nlarge system. In large scale distributed databases which are partitioned you can only\\nachieve either consistency or availability.\\n●\\nHow to generate ssh keys?\\nYou can use ssh-keygen utility to do it.\\n●\\nWhat permission should a private key have?\\n400\\n●\\nYou have proper permissions, how can you switch to a particular user?\\nsudo su -l username\\n●\\nHow can you execute the last command that was run in linux?\\n`!!` will execute the last command'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 26}, page_content='●\\nWithout opening a file you have to create a file and write “hello” in it. How will\\nyou do it?\\necho “hello” > filename\\n●\\nHow to see the IP of a machine?\\n`ip a` or `ifconfig` in older systems.\\n●\\nWhat are in-memory databases?\\nIn memory databases are the ones where which keeps its data in memory which\\nmakes them very fast. Few examples are redis, memcache etc.\\n●\\nWhat do you mean by scalability?\\nScalability means that your system should be able to cope up with the growing use\\nwithout any change in architecture just by adding a few extra machines. Creating\\nscalable systems is very tough.\\n●\\nWhat do you mean by reliability?\\nReliability can be expressed as a system that can work what it is intended to do in\\nharsh circumstances.\\n●\\nWhat is VVV in big data?\\nVelocity, Variety and Volume\\n●\\nWhat are microservices?\\nMicroservice is an architecture in which you try to break up your whole software into\\nsmaller systems and let them do the task that is assigned to them. There are a lot of\\nadvantages that come with it. Few of them are:\\n1. Faster and smaller deployments.\\n2. Small changes can be made without thinking of the whole system.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 27}, page_content='3. Smaller teams can handle their services with ease.\\n●\\nWhat do you mean by monolith?\\nMonoliths are a big piece of software. They are huge code bases. You can say\\nmonolith is the opposite of microservice. Some of the advantages of monolith are :-\\n1) Testing is easier than microservices\\n2) Managing monolith is easier than microservices\\n●\\nWhat do you mean by high availability?\\nHigh availability means that even a few components of your system goes down your\\nsystem should be working fine. For example there are 5 instances of your service\\nrunning, even if your 2 instances go down your service will still be working. This is\\nhigh availability.\\n●\\nWhat are stateless applications?\\nStateless applications are the one which don’t save any data locally on their servers.\\nThis is very important if you want your service to be horizontally scalable.\\nImagine if you are saving some data on disk you can not launch another instance\\nand run the same service on that as it may not be aware of the data on the first\\nmachine and that will cause problems. In these scenarios you generally build\\nstateless service and save the data to remote DB.\\n●\\nWhat is horizontal scaling?\\nHorizontal Scaling means you can scale your service by running more instances of\\nyour service on different locations and don’t need to make any changes to it.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 28}, page_content='●\\nWhat is the difference between scaling out and scaling up?\\nScaling out simply means horizontal scaling in which you launch more instances of\\nthe same machine while in scaling up you do vertical upgrades of the machines.\\n●\\nWhat is session stickiness?\\nIt means that a user who accessed service to a particular instance of will be\\nredirected to the same instance of service based on defined parameters.\\nSession stickiness works on a few parameters that can be any one of headers,\\nroutes or cookies. Based on these parameters the proxy of load balancer takes\\ndecision where to route the traffic.\\n●\\nIn 7 layer architecture, in which layer does IP is used?\\nIt stands in the 3rd layer which is the network layer.\\n●\\nIn 7 layer architecture, in which layer does TCP is used?\\nIt stands in 4th layer which is transport layer\\n●\\nHow to copy a file from one machine to another?\\nYou can use SCP utility.\\n●\\nDo you know which mathematical terms public key encryption uses?\\nPrime numbers and modulo.\\n●\\nHow to see current time in linux?\\ndate\\n●\\nHow to see the difference between two files in linux?\\ndiff file1 file2'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 29}, page_content='●\\nWhat is an ephemeral memory?\\nEphemeral memory is one where the data is lost on a reboot. It is generally faster\\nthan disks and slower than RAM.\\n●\\nWhat is verbose mode?\\nThe Verbose mode is one in which your program emits log about each step and what\\nit is doing. It is used for debugging purposes.\\n●\\nWhat does pipe | does?\\nYou can use this to pass the output of one program as an argument to another one.\\n●\\nHow can you pass output of one script to another in bash?\\nScript2 | script2\\n●\\nWhat is CFS scheduling?\\nCompletely Fair Scheduling is the scheduling algorithm which is by default used in\\nmost of the linux operating systems. It tries to optimize the utilization of CPU while\\nincreasing interactive performance.\\n●\\nWhat do you mean by preemptive scheduling?\\nPreemptive scheduling is one where the CPU can trigger an interrupt to start running\\nthe other high priority task. It is the one in which a process can leave the CPU before\\nreaching its waiting state or final state which is not the case with non-preemptive\\nscheduling. In current days most of the algorithms used in scheduling are\\npreemptive.\\n●\\nWhich system call is used to create a process?\\nfork()'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 30}, page_content='●\\nWhich system call is used to open a file?\\nopen()\\n●\\nDo you know about GDB?\\nGDB stands for GNU debugger. It is debugger and can be attached to many\\nprogramming languages for debugging purposes. Few of these languages are C,\\nC++, go, fortran etc.\\n●\\nWhat is a grub?\\nGrub is a grand unified bootloader. Grub is the first program that runs when you start\\nyour machine. It loads the operating system to the memory and then transfers the\\ncontrol to it.\\n●\\nWhat does ICMP stand for, name one tool that uses it?\\nIt stands for Internet Control Message Protocol. Ping is one of the most common\\ntools that uses it. It is used for debugging networks.\\n●\\nThere is already a file with the name filename. You run this command touch\\nfilename. Now what will happen?\\nIt will change the timestamp of the file.\\n●\\nWhen you see linux man pages you see there are many types of commands\\none is command(2) and other can command(1) or any number what these\\nnumbers specify?\\nThese numbers specify which section these values belong to. This is the list\\n1. User commands'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 31}, page_content='2. System Calls\\n3. C library functions\\n4. Devices and special files.\\n5. File formats and conversions.\\n6. Game et. al.\\n7. Miscellaneous\\n8. System administration tool and daemons.\\n●\\nWhat is tty?\\nTty is a teletypewriter. When you run tty it shows you the file to which the current\\nterminal is attached.\\n●\\nWhat is pty?\\nThese are pseudo teletypes that act as a virtual terminal to process reading and\\nwriting to it but these teletypes are controlled by some other  process.\\n●\\nHow to list all hidden files in a directory?\\nls -a\\n●\\nHow to make a file or script executable?\\nchmod a+x filename\\n●\\nHow to find the files modified in the last 5 days?\\nfind / -mtime -50\\n●\\nHow to find the files accessed in the last 5 days?\\nfind / -atime -50\\n●\\nDo you know what bastian servers are?\\nThese are the jump servers used to get access inside any VPC(Private subnet) It is\\nthe box launched in the Public subnet of VPC to get inside the Private Subnet.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 32}, page_content='●\\nHow to add and remove soft links in linux?\\nFor adding links: ln -s file link\\nFor removing link: unlink\\n●\\nDo you know about TCP jigsaw in congestion control?\\nTCP jigsaw is a graph that gets created when congestion control triggers in TCP.\\nTCP does a slow start and then eventually increases the rate of packets sent one by'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 33}, page_content='one. Once there is a congestion that is detected it decreases the rate to half of\\ncurrent and then repeats the same. When you draw this graph you will see\\nsomething like this.\\n●\\nWhat do you know about packet encapsulation?\\nPacket encapsulation is a process in which the lower levels in the OSI layer\\nencapsulate the packets that are passed to it by the upper layer. For example a\\npacket from a transport layer when moving to a network layer is encapsulated with\\nextra information like header and source destination ip address.\\n●\\nWhat do you mean by VPC peering?\\nVPC is a process in which two VPCs are connected in such a way that they are\\ntreated as a local network.\\n●\\nWhat is the difference between cron and anacron?\\nWith crontab you can schedule a job to be run after any interval or at a particular\\ntime. With anacorn you can schedule a job only on  a daily basis.\\n●\\nWhat are the system calls used for process management?\\nfork() exec() wait() and exit()\\n●\\nWhat are linux aliases?\\nAlias in bash instructs the bash to replace a particular string with a predefined\\ncommand. You can add this alias in .bashrc or or .bash_profile something like this\\nalias l=’ls’\\nSo when you type l, ls will get executed.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 34}, page_content='●\\nHow to run a simple web server using python?\\npython -m SimpleHTTPServer\\n●\\nHow to verify if the given json is valid?\\npython -m json.tool < data.json\\n●\\nWhen you open a terminal you want to execute a few scripts or commands,\\nhow can you do it?\\nYou can put them in .bashrc\\nCloud Specific Questions:\\n●\\nWhat are security groups in aws?\\nSecurity group is a concept in aws where you can define which ports and ips to allow\\nto access any particular entity.\\n●\\nWhat are VPC and subnets?\\nVPC is a separate network that you create to launch your machine which is also\\nknown as vnet. Subnet is a separation inside that vnet and you generally launch\\nmachines according to specific subnets.\\n●\\nWhat are NACL and to which they are attached?\\nNACL or network access control list is a setting on subnet where you can define the\\ndestination and sources that are allowed to pass through this NACL. In short it acts\\nas a firewall.\\n●\\nHow can you connect your machine to the internet from a VPC?\\nYou need an internet gateway to connect to the internet.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 35}, page_content='●\\nHow can you connect two VPCs?\\nVPC peering or ipsec tunnels\\n●\\nWhich VM series in Memory optimized is aws?\\nR series.\\n●\\nWhat are snapshots?\\nSnapshots is a way to create a backup of a machine. It takes the image of the whole\\nmachine and then creates similar machines.\\n●\\nWhat is an AMI?\\nAmazon Machine Image is a way to create images of operating systems or machines\\nwhich you can use to launch new similar machines.\\n●\\nWhat is cloud init?\\nCloud init is a concept in which this is the first script that runs when a machine is\\nspawned by any of the cloud providers. For example user-data in aws.\\n●\\nWhat is IAM?\\nIdentity and access management is a service in aws to manage users and their\\npermissions and policies.\\n●\\nWhat is a lambda?\\nLamba is a service which allows you to run scripts without thinking about machines.\\nThis supports serverless architecture.\\n●\\nWhat is SQS?'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 36}, page_content='Simple Queuing Service is a managed service in aws where you get queues as a\\nservice.\\n●\\nWhich aws service will you use to launch pre pre-defined machine?\\nCloud Formation\\nPython Specific Questions:\\n●\\nTell about threading in python\\nPython is single threaded. Even if you use multi thread in python it will only execute\\none thread at a time. This happens because of a component called GIL or global\\ninterpreter lock. It is used to make python thread safe. If you want to run parallel\\ncode use multiprocessing.\\n●\\nWhich one is better in case of IO bound processes, multithreading or\\nmultiprocessing?\\nMultithreading will work fine in this case as in the IO process the CPU doesn’t do a\\nlot of work but waits for IO to complete.\\n●\\nWhat do you mean by GIL?\\nGlobal Interpreter lock is used to synchronise processes in python and doesn’t allow\\nmultiple pieces of code to execute at the same time.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 37}, page_content='●\\nWhat are decorators in python?\\nDecorators are types of functions which can be used to wrap other functions. With\\nwrapper you can modify the argument, their order and the functionality. We can also\\nassume it like oregano and chilli flakes we put in pizza. The oregano and chilli flakes\\nare the decorator in pizza.\\n●\\nWhat are iterators in python?\\nIterators in python are a type of python which helps in iterating over any group of\\nobjects and can be used with clauses in python. You can get the iter of any object\\nusing iter keyword.\\nExample:\\nA = (1,2,3,4,5)\\nB = iter(A)\\nprint(next(B))\\nprint(next(B))\\nprint(next(B))\\nOUTPUT:\\n1\\n2\\n3\\n●\\nWhat are generators?\\nGenerators are simple python functions but instead of return value they use yield\\nstatements. So they return an iterator object on which when you can next you get the\\nnext data.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 38}, page_content='Generators are very useful as they save memory. How? Let us look at an example or\\ngenerate infinite numbers. This is not possible as there is not enough RAM to save it.\\nBut we can accomplish it using generators. Look at the cook sample below.\\ndef loo():\\ni=0\\nwhile True:\\nyield i\\ni= i+1\\na = loo()                                                                                                                 for i\\nin a:\\nprint(i)\\nYou can see that infinite numbers will start printing. So there were infinite numbers in\\na. But how?  This is what generators do differently. It tries to do lazy processing. It\\nprocesses things when it is required to return the value at that time.\\n●\\nWhat is comprehension?\\nComprehension in python provides us a way to create sequences using shorthand\\nnotations. For example:\\n[ x*x for x in range(1,100)]\\nThis will generate a list with numbers of squares of 1 to 100.\\n●\\nAre tuples mutable?\\nTuples are immutable.\\n●\\nWhat is lambda in python?\\nLambda is a first class function in python. It is also known as an anonymous\\nfunction. They are just like python which don’t need any definitions. They can take\\nany number of arguments. Here is an example of lambda function.\\ng = lambda x:x*x'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 39}, page_content=\"print(g(6))\\nThis function here is calculating squares of any number passed to it.\\n●\\nWhat is the difference between range and xrange?\\nRange function generates the numbers. While Xrange is a generator which\\ngenerates the numbers when required. Also known as lazy evaluation.\\n●\\nHow to see all the attributes of any object?\\ndir()\\n●\\nWhat are *args and **kwargs?\\n*args is used to pass a variable number of arguments to a function. It's actually the *\\nthat allows this capability that this object is iterable. It is used to pass a list of\\narguments.\\nExample:\\ndef fun(*args):\\nfor i in args:\\nprint(i)\\nfun(1,2,3,4,5)\\n**kwargs is used to pass variable number of keyword arguments like below\\ndef fun_call(**kwargs):\\nfor i,j in kwargs.items():\\nprint(i,j)\\nA = {“var1”:”val1”,“var2”:”val2”,“varn”:”valn”}\\nfun_call(valn)\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 40}, page_content='●\\nWhat is pickling in python?\\nPickling is used in python to convert any python object in byte stream and unpickling\\nis the reverse of those. In short it is serialization and deserialization of python\\nobjects.\\n●\\nDo you know what help() does?\\nHelp function is used in python to get the details of the objects or function that is\\npassed to it.\\nUsage: help(object)\\nSystem Design\\nThis can be one of the most important rounds and may help you make small mistakes that\\nyou have made in other rounds. You have to understand the systems in depth that you\\nworked on. There will be a lot of questions that will be asked about your project in depth.\\nBelow are a few questions that you should prepare.\\n1. How did you make sure it is scalable?\\n2. Tell me about failover mechanisms used.\\n3. How will you scale the system to the next level?\\n4. Can you think of any other way to accomplish it?\\nNext you may be given a problem and you have to design a system for the same. Being a\\ndevops you have to make sure that your systems are reliable, failover safe, scalable and\\nmeasurable.\\nWhen you are given a problem you don’t need to rush into the solution. Give it some time\\nand think about it. Try to figure out the exact problem statement and define the scope. After'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 41}, page_content=\"that list down the questions that you want to ask questions. Ask as many questions as you\\nwant. It gives you a better understanding of the problem statement and will help you get the\\npoints that  you can miss if you don’t ask questions.\\nHere are a few points that you must do.\\n1. Understand the question properly.\\n2. Think about questions that will define the scope of the problem.\\n3. Try to limit the scope, don’t start working if you don’t want to keep guessing it.\\nNow let’s see what you should think while approaching the problem. The things that you\\nhave to keep in mind while designing the system are\\n1. Your system must be scalable.\\n2. Must be failsafe.\\n3. Your system must be reliable.\\n4. You should think of the numbers that you must know like below.\\na. Read or write intensive\\nb. Number of  requests per second.\\nc. Amount of data transferred.\\nd. Do you need to design it for multiple data centers?\\ne. Define the data types to save like caches, static content, archived data or\\npersistent data.\\n5. Since you are devops and sre you have to think of the aspects like DNS, Load\\nbalancing and availability. Don’t miss on these.\\nNow let's solve a practice system design problem and try to build up a strategy to approach\\nthese problems.\\nProblem Statement: You have to design a generic worker system that works on apis, gets\\nyou past its endpoint and data. The system makes a request, saves the response and\\npasses you back the data.\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 42}, page_content='Solution:\\n1. Defining the scope.\\nScope consists of designing a server to which you will pass target url to\\nscrape. The server scrapes the data, saves it and then returns the response.\\n2. Questions that should be answered.\\na. Can this system be real time?\\nNo as any website can take its own time to give a response so it\\ncannot be done in real time.\\nb. What response do you need from the request?\\nWe don’t need any response on scrape requests as it is not feasible to\\nget the data and return since the request is made to third party\\nservers.\\nc. Any api to read the data? If so, how many?\\nYes there will be an api to get the scrapped content. When we talk\\nabout scale you can say it is not very much. Say 100 read requests\\nper min.\\nd. How many concurrent requests should it handle?\\nAround 10000 scrape requests and around 100 read requests.\\ne. How much data does it need to save and what content does it need to save?\\nIt needs to save the html content and images. Doesn’t need to bother\\nabout javascript generated pages.\\n3. Numbers to calculate.\\na. How much data to save?\\nWe will take the average size of a website as 1000KB. This means we\\nhave to save 10 GB of data every min. This will produce around\\n10*60*24 ~ 15TB of data daily which is huge.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 43}, page_content=\"b. How to save the data?\\nNow saving this data is a big problem. What we can do is save the\\nresponses as files and then point the domain names to the file path.\\nAnd keep them in some database like mysql. Now how many files will\\nit create daily. 10000*60*24 ~ 14400000. That’s a lot of files. You can\\nsave them in storage like S3.\\nc. Read or write intensively?\\nWe can see that this application is write intensive and has to support\\nvery less number of reads.\\n4. Design.\\nLet's first see the diagram of our base application.\\nWhat we are doing here is there will be a main server to accept the requests. The\\nserver then puts the task in the queue and returns the 201 accepted code.\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 44}, page_content=\"We will run a few workers that will take requested tasks from the queue and make\\nrequests outside and wait for the response to come. Once the response comes the\\nworkers will put the data in blob storage and their index to a mysql.\\nThis was the write flow of the application. Next let's have a look at the read flow of\\nthe application.\\nNow we have a basic application on how it will work. Next we have to think of scale\\nand how we can make changes to it so that it can scale for a large number of\\nrequests. Also we need to add some reliability to it. For that lets see the diagram\\nbelow.\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 45}, page_content='Now let us see what we did here. We simply just add a bit of high availability and\\nreliability and load balancing theories. Lets see first off we put load balancing at DNS\\nlevel. So whenever a device will query for our service it will get multiple IPs so that\\nload can be balanced at that point.\\nNext we added a load balancer behind each resolved IP and behind that there are a\\nset of servers that will serve the request.\\nThese services are stateless so they can be easily scaled horizontally. Next, these\\nservices put the data in the queue to be processed and then workers read the next\\njob and process it, push the results to blob storage and then index into the mysql\\ndatabase.\\nWe also separated out the read servers from the write servers. Though it will not\\nmake much difference as the write servers are not doing anything they are just\\ngetting the request and then putting it in the queue to be processed by the workers.\\nThis was basic on how you should design a system keeping in mind the scalability\\nand reliability. We didn’t put much focus on how to code this example. Coding part\\nyou can try and think on your own. Few pointers are needed to code in a way that\\nthe application is stateless and it can be scaled horizontally.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 46}, page_content=\"So this was basic of how you should do system design. If you try to follow the listed\\napproaches you should be able to figure out details that you may miss if you just\\nstart solving the problem instead of reading it properly and asking proper questions.\\nThese things you should always keep in mind.\\n1. Always think of systems that are scalable, reliable and fault tolerant.\\n2. Ask as many questions as possible.\\n3. This round is supposed to be one in which you can use your educated\\nguesses. Even if you don’t know the solution, use your experience to make\\nan educated guess.\\n4. Try to answer why you are doing it for each component as it will be asked\\nwhen you are done with the system design and in the middle of discussions.\\nProgramming\\n1. Log Parsing\\nYou have logs of the application server and you have to generate a CSV in\\nwhich you will count the number of messages per process per second.\\n2. Health Check\\nWrite a python script that does a continuous health check on a process and\\nstarts it if it's not working.\\n3. Get system stats and send them to an api.\\nWrite a program to get the load average of the machine and send it to the\\nexternal endpoint.\\n4. Verify if the files are copied properly.\\nYou have a list of files in dir1 and dir2 you have to check if all the files are\\ncorrectly copied.\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 47}, page_content='5. Basic programming questions which involve string manipulation.\\nYou are given a string you have to find if a substring exists or not.\\nYou can very easily find these questions on geeksforgeeks.\\n6. File manipulation.\\nSince you are working in devops, one of the most used functions of python\\nwill be open(), which opens a file. So you must know how to open, close,\\nread, write to file.\\n7. Write a python program to get the number of processes running and how many\\nthreads each process has created.\\n8. Write a python program which tells if there is a new user created in the linux system.\\nFew programming practices to follow\\n●\\nAdd readability to your code as much as possible.\\n●\\nThe function name should tell what this function does.\\n○\\nThe function should be visible in one screen. You should not scroll to\\nview the whole function.\\n○\\nTry to write pure functions instead of impure functions. Read here\\nabout pure and impure functions\\n●\\nOne function should do one thing and that thing properly.\\n●\\nLogging is very important.\\n○\\nYou should choose the level of logging very wisely. A lot of logging will\\nmake your application slow.\\n○\\nLess logging you may miss out required info for debugging.\\n●\\nFailures are normal. Fail as early as possible and as loud as possible.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 48}, page_content='●\\nMetrics provides you with a way to keep track of what your code is working with\\nrespect to how it was working earlier.\\n●\\nTry to structure your code in such a way that if you want to add something new\\nyou can do it in minimum effort.\\n●\\nDocumentation is very important. Try to document a project you are about to\\nbuild in advance. This will make your thoughts clear about what you are going to\\nmake and how you will achieve it.\\n●\\nComment wherever is necessary. Your comments will help the person who will\\ntake over code to understand it easily.\\n●\\nYour program should be config driven. Don’t hardcode anything in your code.\\n●\\nTest cases are very important.\\n○\\nYou will have confidence in your code and less bugs will go to\\nproduction.\\n○\\nEdge cases are important to consider.\\n○\\nThere are people who actually do test-driven development. This means\\nthey write the test case first for what they want to achieve and then\\nthey write the code for it.\\n●\\nAlways think that your software may need to interact with other software in the\\nfuture so write it in a way that others can interact with it.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 49}, page_content='Basic Incident management\\nThis is one of the most basic rounds and one of the trickiest ones. This round involves a few\\nvery basic points that you have to keep in mind. Generally you first priority to make the\\nsystem working before starting to debug. Let’s take an example and see how to approach\\nthese problems.\\nIt is 2:00 AM in the morning. You have an application deployed in 7 data centers\\nserving different regions. You started to see increases 5xx from one of the regions\\nwhich is being served from the data center3 out of 7 data centers. You looked at the\\ndeployment list and saw that there is a deployment that went through at 1:45PM. How\\nwill you handle this situation?\\nIn these kinds of scenarios your first preference is to save your applications. Since one of\\nyour data centers is showing errors. Your first step will be to divert the traffic from the\\naffected data center to the data centers which are working totally fine.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 50}, page_content=\"Next thing is since you have seen this behaviour after a deployment that went some time\\nback. You will revert the deployment and inform the developers about the scenario. You\\nmay also be asked whom else to inform. It may be possible that you have to inform your\\nleads about this incident and may need approval for diverting traffic.\\nAfter you have reverted the deployment, you can start moving a small portion of traffic to the\\naffected data center and see if things are going fine. If it's fine you can slowly revert the\\nwhole traffic back to the datacenter.\\nYou have to keep a record of what happened at what exact time and inform the concerned\\npeople. After the incident, you have to write a RCA which is known as the root cause\\nanalysis of the incident, why it happened with a timeline, what could be done to avoid it etc.\\nBelow is an example of RCA.\\nSummary: The system was down from _____to _____ due to ______________\\nSeverity: Level of issue. This describes the impact on your system.\\nBusiness Impact: Mention if there was any business loss.\\nTimeline: When it started, at what time you took what steps, everything with time.\\nIssue: Elaborate the issue in details\\nGraphs or evidence: Diagram of graphs that proves that whatever you mentioned in the\\nissue is correct.\\nPrecautions in future: Suggest steps that can be taken to avoid this scenario in future.\\nRelated documents: Further documents to support your claim of how to fix the problem.\\nTo practice try to write the above points for the incident that is given.\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 51}, page_content=\"Basic TroubleShooting\\nGenerally you will be given a live system to debug. It may be a web server that you have to\\ndebug or some process or networking error. The topics that you should be aware in these\\nround are below\\n1. Web Servers and reverse proxy like Apache, httpd, nginx, haproxy etcs. Their\\nconfiguration and where to see the logs.\\n2. Iptables\\n3. Linux permissions\\n4. Traceroute, ping, netstat etc for network debugging.\\nLet's see some basic troubleshooting problems.\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 52}, page_content=\"1. There is an apache web server which is not able to open a file and it is giving 403\\npermission denied?\\nThe problem is due to permission as it says. You have to give apache users access\\nto read, write and execute. You can simply make it the owner of that file by using this\\ncommand. chown apacheuser:apacherusergroup file\\n2.\\nThere is a problem where you can see that whatever packet you want to send to an\\nIP is getting lost. What will you do?\\nThis problem can be related to iptables. Read about basic IP tables commands and\\nusage to figure the problem out.\\n3. You are facing a problem where you see that your system is not able to do name\\nserver resolution. What will you check?\\nWe will start the checks by checking the nameservers list in /etc/resolv.conf, then we\\nwill check if these are able to connect on port 53 which is used by DNS. We can use\\ntelnet for that. If it's not reachable we have to see the path it is trying to take and if\\nthere is some restriction and at what hop. We can check that using Traceroute.\\nThese were some quick questions that you may get to resolve and these are standard for\\ndevops. Read about the tools that you use in day to day devops life.\\nTroubleshooting is something which comes with experience. But if you are stuck you can try\\nfollowing approaches.\\n1. People generally develop hypotheses as what must be wrong. Don’t start checking\\nthese hypotheses.\\n2. First of all check the resources of the system like CPU, Memory and disk and then\\nhow much they are used and if there is any pressure on them.\\n3. You will find people doing a restart as a solution to many problems. Mind it restart is\\nnot a solution. It is just a way to show you are lazy and don’t want to debug rather fix\\nthe system and live with the probability that it will happen again in future.\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 53}, page_content='4. Try to remove the possibilities that you think can be the reason one by one. Mind it\\none change at a time. If you start making multiple changes you may get stuck as\\nwhat change has fixed it.\\n5. Understanding the flow of the system which you are managing will help you to reach\\nthe problem faster.\\n6. Provision your system in such a way that you can see metrics and logs very easily\\nand search in them.\\nCode review\\nIn the code review round you will be given code snippets and will be asked to check for\\nbugs in code and how you can write the code in a better way. Try focusing on writing the\\ncode in a better way like memory efficient, cpu efficient instead of focusing on finding syntax\\nerrors. Try doing code review of the below code snippets.\\nCode 1. Read the code below and try to figure out what could be the problem ir how\\nyou can improve it?\\na = open(“filename”,”r”)'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 54}, page_content='data = a.read()\\nSolution:\\nFile is not closed. You can avoid this using context managers.\\nCode 2. Read the code below and try to figure out what could be the problem if how\\nyou can improve it?\\nfile = open(\"test.file\")\\nun_counter,err_counter,suc_counter = 0,0,0\\ndata = file.readlines()\\nfor line in data:\\nif line.startswith(\"Unknown\"):\\nun_counter = un_counter + 1\\nif line.startswith(\"Error\"):\\nerr_counter = err_counter + 1\\nif line.startswith(\"Success\"):\\nsuc_counter = suc_counter + 1\\nprint(un_counter, err_counter, suc_counter)\\nSolution:\\nLook at the comments below\\n# You can use context manager to open file.\\nfile = open(\"test.file\")\\nun_counter,err_counter,suc_counter = 0,0,0\\n# Since file can be very big\\n# reading it line by line makes more sense instead of reading all the lines.\\n#So use file.readline() instead of file.readlines.\\ndata = file.readlines()\\n.\\nfor line in data:\\nif line.startswith(\"Unknown\"):\\nun_counter = un_counter + 1'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 55}, page_content='if line.startswith(\"Error\"):\\nerr_counter = err_counter + 1\\nif line.startswith(\"Success\"):\\nsuc_counter = suc_counter + 1\\nprint(un_counter, err_counter, suc_counter) // File is not closed.\\nAs discussed before put your more focus on looking for errors that can crash the system\\nlike memory consumption in these scenarios instead of putting focus on syntax. No one will\\ngive you code to check for the system. If they are I don’t know what to say here.\\nCode 3. Look at the code below and comment. The task of the code is to read the\\nnumber of Unknown, Error, Success starting lines from a continuous stream. This\\nmeans that file test.file is continuously increasing.\\nimport time\\nfile = open(\"test.file\")\\nvisited_lines = []\\nun_counter,err_counter,suc_counter = 0,0,0\\nline = file.readline()\\nwhile line:\\nif line not in visited_lines:\\nvisited_lines.append(line)\\nelse:\\ncontinue\\nif line.startswith(\"Unknown\"):\\nun_counter = un_counter + 1\\nif line.startswith(\"Error\"):\\nerr_counter = err_counter + 1\\nif line.startswith(\"Success\"):'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 56}, page_content='suc_counter = suc_counter + 1\\nprint(un_counter, err_counter, suc_counter)\\nSolution\\nLook at the comments below :-\\nimport time\\nfile = open(\"test.file\")        // again could have used context manager.\\nvisited_lines = []\\nun_counter,err_counter,suc_counter = 0,0,0\\nline = file.readline()\\nwhile line:\\nif line not in visited_lines:\\nvisited_lines.append(line)\\n# This will be a huge array if the file is continuously increasing as you are keeping\\n# literally the whole file in memory because of this. Think about what could be a\\nbetter\\n# way to achieve this.\\nelse:\\ncontinue\\nif line.startswith(\"Unknown\"):\\nun_counter = un_counter + 1\\nif line.startswith(\"Error\"):\\nerr_counter = err_counter + 1\\nif line.startswith(\"Success\"):\\nsuc_counter = suc_counter + 1\\nline = file.readline()  // To read the next line else it will just read the first line\\nprint(un_counter, err_counter, suc_counter) // file not closed.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 57}, page_content='These were some examples. You may get problems similar to these or different smaller or\\nbigger ones. What you have to make sure is you are able to read and understand the code\\nand how much resource utilization it is doing. Are there any infinite loops, any where there\\nis bad use of memory or things like that. At the end if you are a python programmer, they\\ncan also ask you if you can provide a more pythonic way to achieve the solution. To prepare\\nfor code round, read more python code related to log parsing, file operations, regex, string\\nmanipulation etc.\\nTools in devops\\nLets first list down the different components that devops has to take care of and then we will\\ntry and list down a few of the best tools.\\n1. Spawning Machines.\\n2. Build systems\\n3. Provisioners\\n4. Monitoring Utilities\\n5. Logging Utilities\\n6. Alerting Utilities'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 58}, page_content='7. Visualization\\n8. Security\\n9. Cluster orchestrator to deploy.\\n10. Password and secret manager.\\n11. Event driven response systems.\\n12. Artifact storage\\nSpawning Machines: This is a task that actually starts the machines. The tools that can do\\nthis for you are terraform, pulumi. Terraform has evolved and it can work with most of the\\nclients like AWS , Azure and GCP.\\nBuild Systems: Jenkins, Travis, CircleCI are the popular tools for building systems. These\\nare the systems that are used to run scripts, build container images, etc. These systems\\ncan do ad hoc tasks for you.\\nProvisioners: Chef, Puppet, Ansible and salt are few of the very popular options.\\nProvisioners are the system which does the basic installations on the machine.\\nMonitoring Utilities: Prometheus is one the most famous open source tools that you can\\nuse. Beside this there are tools like data dog, new relic etc that do this for you. These\\nsystems need some exporter to either send data or expose data.\\nLogging Utilities: For logging you need log shippers first and then a system to process it.\\nTwo well known systems for this are ELK [Elasticsearch Logstash and Kibana] and one\\nother is graylog which uses mongo, elastic search in the backend. For log shipping you can\\nuse rsyslog, fluentd etc.\\nAlerting Utilities: Sensu, pagerduty, prometheus can do the alerting for you.\\nVisualization: Grafana and Kibana are very famous open source projects for this purpose.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 59}, page_content='Security: Security is something that has a wide range. Talking about them is very tough,\\nhere are few tools that will help you in managing security.\\nCluster Orchestration: Kubernetes, mesos, docker swarm are very good options.\\nPassword and security manager: Vault from hashicorp.\\nEvent driven automation system: Stackstorm is a very good tool for that.\\nArtifact storage: Artifactory, docker hub are good options.\\nThings to read in python that are important\\n1. String and array manipulation\\nYou should read about basic string manipulations like replacing a few words,\\nsearching for a pattern, array traversal and manipulation.\\n2. Reading and writing to files\\nHow to open a file in reading and writing mode and putting and reading data\\nfrom file.\\n3. Make request to remote server\\nIn this section read about how to use requests library of python.\\n4. Parse JSON, YML and other file formats\\nYou can read about json, pyyaml libraries and other such data formats.\\n5. How to scrape a webpage?\\nBeautifulSoup and XML can be very useful.\\n6. Threading model of python\\nThreading and multiprocessing library\\n7. Iterators, Generators and list comprehension'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 60}, page_content='These are basic topics that can be very helpful because these actually define\\nwhat you call pythonic style.\\nDebugging tips and tools that you can use in bash.\\n-x option: This option prints the commands and their arguments as they are getting\\nexecuted. Let try and run a script\\n#!/bin/bash\\nset -x\\nVAR1 = “somevalue”\\necho “$VAR1”\\nOUTPUT:'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 61}, page_content=\"+\\nVAR1=somevalue\\n+\\necho asdasd\\nasdasd\\nWhat it did is actually replaced the variable name with value where the variable is being\\nused.\\nThis option is very useful when you try to debug your code and want to see what is\\nhappening at each step of the code.\\n-e option:\\nThis option exits your code immediately if a command returns a non zero exit status. Let's\\nhave a look at an example.\\n#!/bin/bash\\nset -e\\nls /file/path/which/doesnt/exists\\necho “Reached this line”\\nOUTPUT:\\nls: cannot access ‘/path’ :No such file or directory\\nAs you can see it exits at the moment it gets a non zero exit status by ls command.\\n-v option:\\nIt prints the commands before executing it. The difference between -v and -x is that it\\ndoesn’t expand the variable and replace the actual values.\"), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 62}, page_content='These are few options that can be very helpful when debugging your bash scripts. These\\ncommands are generally used together to get the more context into the problem like -x and\\n-e can be used to see just before exit what are the values of the variables.\\nTCP DUMP:\\nIt can be used to take a dump of tcp packet and can use programs like wireshark to\\nanalyze it.\\nTRACEROUTE:\\nIt is used to trace the route which any packet will take to reach the destination.\\nTelnet:\\nIt is used to check if you are able to connect to a given address and port.\\ndf -Th:\\nTo look at the disk space available in the system in a human friendly way.\\nfree -m:\\nTo see free memory.\\nFew words for you\\nWhen you go for these interviews, most of the time they will try to see your thinking ability\\nand how you approach the problem. Don’t rush into the problem, give it some time and\\nanalyze it. Once you are sure of the problem try to give the most obvious solution instead of\\nrushing into the most optimized solution. Your first priority should be that your solution\\nworks, once you have a basic solution ready then you can try and optimize that solution or\\ngo for better approaches.'), Document(metadata={'producer': 'Skia/PDF m99 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'file_path': '../data/pdf/SRE DevOps Interview CheatSheet.pdf', 'total_pages': 64, 'format': 'PDF 1.7', 'title': 'Interview preparation and questions Devops', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 63}, page_content='Whenever you are trying to solve any problem try to think loud. It is very important for the\\ninterviewer to hear what you are thinking. If he is not hearing you, even if you are thinking in\\nthe right direction but not reaching the solution he cannot help. But if he is hearing your\\nthought process he can help you to reach the solution. This is the kind of interview that I like\\nthe most.\\nWhen we talk about system design interviews, they can be one of the trickiest rounds. Give\\nyourself time to define the scope of the solution. Then approach the solution. Try to design\\nyour solution in a way that it is extensible. You should always keep in mind about scalability,\\navailability and reliability in mind while designing your solution.\\nDon’t think that any solution is something that you cannot think of. Everything can be solved\\nusing the first principle. If you are stuck, take a step back and think of solving it using the\\nvery basic principles. Don’t give up easily, it will give a wrong idea about your attitude. At\\nleast try to start the solution. It is not wrong for you to ask the interviewer a hint. But his\\ndepends upon person to person how he takes your request of giving him hints.\\nTry to mould your interview in a way that you are driving it instead of the interviewer. Focus\\nmore on the topics you know and go into details of those topics. This will help you drive it.\\nAtlast be confident and trust yourself you can crack any interview with proper preparation.'), Document(metadata={'producer': 'Skia/PDF m142 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/Diego Ramos - Cover Letter.pdf', 'file_path': '../data/pdf/Diego Ramos - Cover Letter.pdf', 'total_pages': 1, 'format': 'PDF 1.4', 'title': 'Diego Ramos - Cover Letter', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}, page_content=\"September 25, 2025 \\nDear Hiring Manager, \\nI am writing with great interest to apply for the AVP Software Engineer - Gen AI position at \\nMoody's. With over 14 years of experience at Intel building software and automation systems, I \\nhave a strong record of driving innovation and measurable results in fast paced engineering \\nenvironments. I'm truly excited by the chance to apply my experience with intelligent systems to \\nthe pioneering work Moody's is doing in financial analytics. \\nIn my current role as Senior Product Development & Automation Engineer, I recently led the \\ndevelopment of an AI powered validation framework system that reduced pattern release cycles \\nfrom over 10 hours to just 1. A key feature of this system was an intelligent chatbot I built using \\nOllama and Python, which provided real time support to engineers and helped identify critical \\npre-silicon defects, and achieved a 100% pass yield on first silicon.  \\nBeyond the technical work, I served as Product Owner and Tech Lead for the Costa Rica team. I \\nenjoyed guiding our local group and collaborating with teams in Austin, Santa Clara, and \\nBangalore to deliver the first on time product launch in a decade, an effort that earned us an \\nIntel Achievement Award. \\nMy skills include Python, C#, cloud native CI/CD pipelines, and modern AI/ML frameworks. I've \\nbeen actively diving into Generative AI and MLOps, using tools like LangChain, Ollama, N8N \\nand AWS SageMaker to build prototypes and upgrade our existing workflows. \\nThank you for considering my application. I look forward to the opportunity to help and \\ncontribute to your team's success. \\nSincerely, \\nDiego Ramos Olmedo\\u200b\\nSan José, Costa Rica\\u200b\\nEmail: drolmedoia@gmail.com\\u200b\\nPhone: +506 8845 5243\\u200b\\nLinkedIn: linkedin.com/in/diegoolmedocr\")]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "\n",
    "\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/pdf/\",\n",
    "    glob=\"*.pdf\", # Cargar solo archivos .txt -> este es el patron a matchear\n",
    "    loader_cls=PyMuPDFLoader, # Clase de cargador a usar\n",
    "    show_progress=False # Mostrar progreso de carga)\n",
    ")\n",
    "\n",
    "pdf_documents = dir_loader.load()\n",
    "print(pdf_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79dde48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pdf_documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_proyecto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
